# Data Model: Module 4 - Vision-Language-Action

## Overview
This document defines the data models and entities for Module 4: Vision-Language-Action, focusing on the educational content and system components that will be implemented in the Docusaurus-based educational book.

## Core Entities

### 1. Voice Processing Pipeline

**Entity**: VoiceProcessingPipeline
- **Description**: Converts speech input to actionable text commands
- **Attributes**:
  - audio_input: bytes (raw audio data)
  - processed_text: string (transcribed text)
  - confidence_score: float (0.0-1.0)
  - error_handling: object (error details if any)
  - timestamp: datetime (when processed)
- **Relationships**:
  - Connects to Cognitive Planning Engine
- **Validation rules**:
  - confidence_score must be between 0.0 and 1.0
  - processed_text must not be empty when confidence > 0.5

### 2. Command Parser

**Entity**: CommandParser
- **Description**: Parses natural language commands and extracts actionable elements
- **Attributes**:
  - input_text: string (raw command text)
  - parsed_command: string (normalized command type)
  - parameters: object (command-specific parameters)
  - alternatives: array (possible interpretations)
- **Relationships**:
  - Receives from Voice Processing Pipeline
  - Outputs to Cognitive Planning Engine
- **Validation rules**:
  - parsed_command must be one of predefined command types
  - parameters must match expected format for command type

### 3. Cognitive Planning Engine

**Entity**: CognitivePlanningEngine
- **Description**: Interprets high-level commands and generates action sequences
- **Attributes**:
  - input_command: string (high-level command)
  - robot_capabilities: array (available robot actions)
  - action_sequence: array (sequence of actions to execute)
  - context: object (robot state and environment info)
  - generated_at: datetime (timestamp of generation)
- **Relationships**:
  - Receives from Command Parser
  - Outputs to Action Execution System
- **Validation rules**:
  - action_sequence must contain valid ROS 2 action definitions
  - context must be properly formatted for LLM prompting

### 4. Action Sequence Item

**Entity**: ActionSequenceItem
- **Description**: Individual action in a sequence generated by the cognitive planner
- **Attributes**:
  - action: string (action type, e.g., "move_forward", "turn_left")
  - parameters: object (action-specific parameters)
  - description: string (explanation of why this action is needed)
  - expected_outcome: string (what should happen after this action)
- **Relationships**:
  - Part of Action Sequence from Cognitive Planning Engine
  - Executed by Action Execution System
- **Validation rules**:
  - action must be one of supported robot capabilities
  - parameters must match expected schema for action type

### 5. Action Execution System

**Entity**: ActionExecutionSystem
- **Description**: Executes ROS 2 action sequences on the humanoid robot
- **Attributes**:
  - action_sequence: array (sequence of actions to execute)
  - robot_state: object (current robot state)
  - execution_status: string (current status: pending, executing, completed, failed)
  - feedback: object (execution feedback)
  - execution_log: array (log of executed actions)
- **Relationships**:
  - Receives from Cognitive Planning Engine
  - Provides feedback to Integration Framework
- **Validation rules**:
  - action_sequence must be properly formatted
  - robot_state must be updated after each action execution

### 6. Integration Framework

**Entity**: IntegrationFramework
- **Description**: Combines all components into a cohesive autonomous system
- **Attributes**:
  - components: object (references to all system components)
  - workflow_state: string (current state of the workflow)
  - error_handling: object (error recovery strategies)
  - monitoring_data: object (system performance metrics)
- **Relationships**:
  - Orchestrates all other entities
- **Validation rules**:
  - All components must be properly initialized
  - Workflow state must follow valid state transitions

## Data Flow Models

### Voice Command Processing Flow
```
Audio Input → VoiceProcessingPipeline → CommandParser → CognitivePlanningEngine
```

### Action Execution Flow
```
CognitivePlanningEngine → ActionExecutionSystem → Robot Actions
```

### Full System Flow
```
Voice Command → VoiceProcessingPipeline → CommandParser → CognitivePlanningEngine → ActionExecutionSystem → Robot Actions
```

## State Models

### Voice Processing States
- `recording`: Audio is being recorded
- `transcribing`: Audio is being converted to text
- `parsing`: Text is being parsed for commands
- `complete`: Processing complete with result
- `error`: Processing failed with error

### Action Execution States
- `pending`: Action sequence waiting to execute
- `executing`: Currently executing actions
- `paused`: Execution temporarily paused
- `completed`: All actions completed successfully
- `failed`: Execution failed at some point
- `cancelled`: Execution was cancelled

## Validation Rules

### Cross-Entity Validation
- ActionSequenceItem.action must match one of the robot capabilities in CognitivePlanningEngine.context
- CommandParser.parsed_command should be consistent with CognitivePlanningEngine.input_command
- ActionExecutionSystem.robot_state should be updated based on executed ActionSequenceItem actions

### Business Logic Validation
- VoiceProcessingPipeline.confidence_score should be checked before passing to CommandParser
- CognitivePlanningEngine.action_sequence should not exceed reasonable length for educational examples
- ActionExecutionSystem.execution_log should capture all executed actions for debugging

## API Contracts (Conceptual)

### Voice Processing Interface
```
POST /process_voice
Request: { audio_data: bytes }
Response: { text: string, confidence: float, alternatives?: string[] }
```

### Cognitive Planning Interface
```
POST /plan_actions
Request: { command: string, context?: object }
Response: { action_sequence: ActionSequenceItem[] }
```

### Action Execution Interface
```
POST /execute_sequence
Request: { action_sequence: ActionSequenceItem[] }
Response: { status: string, execution_log: object[] }
```